{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W207 Forest Cover - KNN v2\n",
    "\n",
    "## Plan\n",
    "\n",
    "#### Feature Engineering\n",
    "\n",
    "- More data cleaning, removing useless data columns\n",
    "\n",
    "- Feature engineering: using only the most important features\n",
    "\n",
    "- Feature engineering: combine some of the soil types\n",
    "\n",
    "#### Error Analysis\n",
    "\n",
    "- Confusion matrix: find out which types give the most problems\n",
    "\n",
    "- Any clue from EDA?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('train.csv')             # read training data\n",
    "data_test = pd.read_csv('test.csv')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(data_train, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Elevation', 'Aspect', 'Slope',\n",
       "       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
       "       'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n",
       "       'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points',\n",
       "       'Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3',\n",
       "       'Wilderness_Area4', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3',\n",
       "       'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8',\n",
       "       'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n",
       "       'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16',\n",
       "       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n",
       "       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n",
       "       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n",
       "       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n",
       "       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n",
       "       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40',\n",
       "       'Cover_Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to keep track of things\n",
    "target = df_train.columns[-1]\n",
    "all_features_ALL = df_train.columns[1:-1]\n",
    "\n",
    "num_features = df_train.columns[1:11]\n",
    "cat_features_ALL = df_train.columns[11:-1]\n",
    "\n",
    "wild_features = df_train.columns[11:15]\n",
    "soil_features_ALL = df_train.columns[15:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove constant Soil_Type7 and Soil_Type15\n",
    "all_features = all_features_ALL.drop(['Soil_Type7', 'Soil_Type15'])\n",
    "cat_features = cat_features_ALL.drop(['Soil_Type7', 'Soil_Type15'])\n",
    "soil_features = soil_features_ALL.drop(['Soil_Type7', 'Soil_Type15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top17_features = all_features_ALL[[0,5,9,13,3,4,6,1,8,7,23,51,16,2,52,10,12]]\n",
    "\n",
    "top10_features = all_features_ALL[[0,5,9,13,3,4,6,1,8,7]]\n",
    "\n",
    "top5_features = all_features_ALL[[0,5,9,13,3]]\n",
    "\n",
    "top2_features = all_features_ALL[[0,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Elevation', 'Horizontal_Distance_To_Roadways',\n",
       "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area4',\n",
       "       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
       "       'Hillshade_9am', 'Aspect', 'Hillshade_3pm', 'Hillshade_Noon',\n",
       "       'Soil_Type10', 'Soil_Type38', 'Soil_Type3', 'Slope', 'Soil_Type39',\n",
       "       'Wilderness_Area1', 'Wilderness_Area3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top17_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. KNN Pipeline\n",
    "\n",
    "- input a list of features\n",
    "\n",
    "- separate features into numeric and categorical\n",
    "\n",
    "- using StandardScaling on the numeric features\n",
    "\n",
    "- combine numeric and categorical features\n",
    "\n",
    "- PCA optional\n",
    "\n",
    "- fit KNN\n",
    "\n",
    "### Note:\n",
    "\n",
    "- Adding MinMaxScaler and Normalizer doesn't seem to help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elevation',\n",
       " 'Aspect',\n",
       " 'Slope',\n",
       " 'Horizontal_Distance_To_Hydrology',\n",
       " 'Vertical_Distance_To_Hydrology',\n",
       " 'Horizontal_Distance_To_Roadways',\n",
       " 'Hillshade_9am',\n",
       " 'Hillshade_Noon',\n",
       " 'Hillshade_3pm',\n",
       " 'Horizontal_Distance_To_Fire_Points']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = top17_features\n",
    "\n",
    "num_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, Imputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# STEP 1: Define the features  #########################################\n",
    "def get_num_features(features):\n",
    "    num_features = [item for item in features if 'Soil' not in item and 'Wilderness' not in item ]\n",
    "    return num_features\n",
    "\n",
    "def get_cat_features(features):\n",
    "    cat_features = [item for item in features if 'Soil' in item or 'Wilderness' in item ]\n",
    "    return cat_features\n",
    "\n",
    "features = top2_features\n",
    "\n",
    "num_features = get_num_features(features)\n",
    "cat_features = get_cat_features(features)\n",
    "\n",
    "# STEP 2: Define the KNN pipeline ######################################\n",
    "\n",
    "def select_num_features(X):\n",
    "    return X[num_features]\n",
    "\n",
    "def select_cat_features(X):\n",
    "    return X[cat_features]\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "num_feature_pipeline = Pipeline(steps=[\n",
    "    ('select', FunctionTransformer(select_num_features, validate=False)),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_feature_pipeline = Pipeline(steps=[\n",
    "    ('select', FunctionTransformer(select_cat_features, validate=False) )    \n",
    "])\n",
    "\n",
    "fu = FeatureUnion([\n",
    "    ('numeric', num_feature_pipeline),\n",
    "    ('categorical', cat_feature_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_num = 10\n",
    "\n",
    "knn_pipe = Pipeline(steps=[\n",
    "    ('preprocess', fu),\n",
    "    ('predict', KNeighborsClassifier(n_neighbors=knn_num))\n",
    "])\n",
    "\n",
    "# knn_pipe.fit(df_train, df_train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STEP 3: Train the KNN_pipe and Make predictions ########################\n",
    "knn_pipe.fit(data_train, data_train[target])\n",
    "\n",
    "pred = knn_pipe.predict(data_test)\n",
    "ID = data_test.Id\n",
    "\n",
    "# STEP 4: Write to file for Kaggle Submission #############################\n",
    "data_out = []\n",
    "for i in range(len(ID)):\n",
    "    data_out.append({'ID':ID.iloc[i], 'Cover_Type':pred[i]})\n",
    "\n",
    "import csv\n",
    "with open('test_submission_top2_knn_' + str(knn_num) + '.csv', 'wt') as fout:\n",
    "    cout = csv.DictWriter(fout, ['ID','Cover_Type'])\n",
    "    cout.writeheader()\n",
    "    cout.writerows(data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Scores of KNN Pipeline on Kaggle \n",
    "\n",
    "Use all_features, top17_features, top10_features, top5_features, top2_features and test the above pipeline with knn=1,2,5,10 and score on Kaggle, following are the results:\n",
    "\n",
    "### all_features\n",
    "\n",
    "- knn = 1: 0.6906\n",
    "\n",
    "- knn = 2: 0.68584\n",
    "\n",
    "- knn = 5: 0.64546\n",
    "\n",
    "- knn = 10: 0.61504\n",
    "\n",
    "\n",
    "### top17_features\n",
    "\n",
    "- knn = 1: 0.65998\n",
    "\n",
    "- knn = 2: 0.66320\n",
    "\n",
    "- knn = 5: 0.62491\n",
    "\n",
    "- knn = 10: 0.59760\n",
    "\n",
    "\n",
    "### top10_features\n",
    "\n",
    "- knn = 1: 0.63003\n",
    "\n",
    "- knn = 2: 0.63973\n",
    "\n",
    "- knn = 5: 0.59013\n",
    "\n",
    "- knn = 10: 0.55603\n",
    "\n",
    "\n",
    "### top5_features\n",
    "\n",
    "- knn = 1: 0.65710\n",
    "\n",
    "- knn = 2: 0.65603\n",
    "\n",
    "- knn = 5: 0.61171\n",
    "\n",
    "- knn = 10: 0.58272\n",
    "\n",
    "\n",
    "### top2_features\n",
    "\n",
    "- knn = 1: 0.48068\n",
    "\n",
    "- knn = 2: 0.52666\n",
    "\n",
    "- knn = 5: 0.50603\n",
    "\n",
    "- knn = 10: 0.50100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis\n",
    "\n",
    "#### ROC curve is not applicable in this case, it is strictly restricted to binary cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test[target]                # get correct labels\n",
    "y_pred_knn = knn_pipe.predict(df_test)  # get predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.71      0.73       552\n",
      "          2       0.81      0.62      0.70       561\n",
      "          3       0.80      0.75      0.78       530\n",
      "          4       0.91      0.96      0.94       563\n",
      "          5       0.80      0.94      0.87       513\n",
      "          6       0.79      0.84      0.81       529\n",
      "          7       0.89      0.96      0.92       532\n",
      "\n",
      "avg / total       0.82      0.82      0.82      3780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "F1_score_test = f1_score(y_test, y_pred_knn, average='weighted').round(4)\n",
    "report_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "# print(F1_score_test)\n",
    "print(report_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross-validation score\n",
    "\n",
    "We would like to get a better estimate of the performance without contaminating the test data. Try using cross-validation to estimate the performance.\n",
    "\n",
    "(The results seem similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7389 0.7617 0.7615 0.7449 0.743 ]\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores_knn = cross_val_score(knn_pipe, df_train, df_train[target], cv=5)\n",
    "print(scores_knn.round(4))\n",
    "print(scores_knn.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[391  68   2   0  27   7  57]\n",
      " [102 346  10   1  77  16   9]\n",
      " [  0   3 400  37   9  81   0]\n",
      " [  0   0  14 543   0   6   0]\n",
      " [  2   6  13   0 483   9   0]\n",
      " [  0   3  58  17   6 445   0]\n",
      " [ 21   1   0   0   1   0 509]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "\n",
    "confusion_knn = confusion_matrix(y_test, y_pred_knn, labels=[1,2,3,4,5,6,7])\n",
    "print(confusion_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commnets:\n",
    "\n",
    "- Cover_Types 4 and 7 have the best performance, from EDA, Cover_Type4 is the one live at the lowest elevation, Cover_Type7 is the one live at the highest elevation;\n",
    "\n",
    "- There is a lot of confusing between 1 and 2: they live in similar elevations just below 7, there is also a lot of confusion between 1 and 7;\n",
    "\n",
    "- Confusion between 6 and 3, 6 and 4 can also be explained by the closeness in elevation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Logistic Regression Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_pipe = Pipeline(steps=[\n",
    "    ('preprocess', fu),\n",
    "    ('predict', LogisticRegression(penalty='l2', C=2.0))\n",
    "])\n",
    "\n",
    "lr_pipe.fit(df_train, df_train[target])\n",
    "\n",
    "y_pred_lr = lr_pipe.predict(df_test)  # get predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.39      0.50       552\n",
      "          2       0.44      0.41      0.43       561\n",
      "          3       0.49      0.33      0.39       530\n",
      "          4       0.56      0.85      0.68       563\n",
      "          5       0.39      0.79      0.53       513\n",
      "          6       0.29      0.00      0.01       529\n",
      "          7       0.74      0.94      0.83       532\n",
      "\n",
      "avg / total       0.51      0.53      0.48      3780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_lr = classification_report(y_test, y_pred_lr)\n",
    "print(report_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross-validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5262 0.5322 0.5388 0.5344 0.5325]\n",
      "0.5328\n"
     ]
    }
   ],
   "source": [
    "scores_lr = cross_val_score(lr_pipe, df_train, df_train[target], cv=5)\n",
    "print(scores_lr.round(4))\n",
    "print(scores_lr.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[144 158   0   0  97   1 152]\n",
      " [ 49 236   7   1 219  18  31]\n",
      " [  0  38 163 191  53  85   0]\n",
      " [  0   0 111 450   2   0   0]\n",
      " [  3 168  10   0 319  13   0]\n",
      " [  0  53 160 165  54  97   0]\n",
      " [ 27   0   0   0   5   0 500]]\n"
     ]
    }
   ],
   "source": [
    "confusion_lr = confusion_matrix(y_test, y_pred_lr, labels=[1,2,3,4,5,6,7])\n",
    "print(confusion_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check LR score on Kaggle\n",
    "\n",
    "- all_features: 0.67 on test, 0.5603 on Kaggle\n",
    "\n",
    "- top17_features: 0.62 on test, 0.4916 on Kaggle\n",
    "\n",
    "- top10_features: 0.58 on test, 0.45328 on Kaggle\n",
    "\n",
    "- top5_features: 0.53 on test, 0.42169 on Kaggle\n",
    "\n",
    "- top2_features: 0.51 on test, 0.39383 on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STEP 3: Train the KNN_pipe and Make predictions ########################\n",
    "lr_pipe.fit(data_train, data_train[target])\n",
    "\n",
    "pred = lr_pipe.predict(data_test)\n",
    "ID = data_test.Id\n",
    "\n",
    "# STEP 4: Write to file for Kaggle Submission #############################\n",
    "data_out = []\n",
    "for i in range(len(ID)):\n",
    "    data_out.append({'ID':ID.iloc[i], 'Cover_Type':pred[i]})\n",
    "\n",
    "import csv\n",
    "with open('test_submission_top5_lr_pipe.csv', 'wt') as fout:\n",
    "    cout = csv.DictWriter(fout, ['ID','Cover_Type'])\n",
    "    cout.writeheader()\n",
    "    cout.writerows(data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Random Forest Pipeline\n",
    "\n",
    "### Note:\n",
    "\n",
    "- increase the RF n_estimators from 100 to 500 improves F1 score by 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_pipe = Pipeline(steps=[\n",
    "    ('preprocess', fu),\n",
    "    ('predict', RandomForestClassifier(n_estimators=500, n_jobs=-1, oob_score=True, random_state=121))\n",
    "])\n",
    "\n",
    "rf_pipe.fit(df_train, df_train[target])\n",
    "\n",
    "y_pred_rf = rf_pipe.predict(df_test)  # get predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.55      0.56       552\n",
      "          2       0.54      0.45      0.49       561\n",
      "          3       0.40      0.37      0.38       530\n",
      "          4       0.65      0.72      0.68       563\n",
      "          5       0.68      0.79      0.73       513\n",
      "          6       0.44      0.42      0.43       529\n",
      "          7       0.79      0.84      0.82       532\n",
      "\n",
      "avg / total       0.58      0.59      0.58      3780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "print(report_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross-validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5883 0.6035 0.6049 0.6068 0.619 ]\n",
      "0.6045\n"
     ]
    }
   ],
   "source": [
    "scores_rf = cross_val_score(rf_pipe, df_train, df_train[target], cv=5)\n",
    "print(scores_rf.round(4))\n",
    "print(scores_rf.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[410  79   0   0  10   3  50]\n",
      " [101 379  12   0  49  17   3]\n",
      " [  0   3 442  26   3  56   0]\n",
      " [  0   0  12 547   0   4   0]\n",
      " [  0  14   9   0 483   7   0]\n",
      " [  0   4  37   7   3 478   0]\n",
      " [ 18   2   0   0   0   0 512]]\n"
     ]
    }
   ],
   "source": [
    "confusion_rf = confusion_matrix(y_test, y_pred_rf, labels=[1,2,3,4,5,6,7])\n",
    "print(confusion_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check RF score on Kaggle\n",
    "\n",
    "- all_features: 0.85 on test, 0.7549 on Kaggle\n",
    "\n",
    "- top17_features: 0.84 on test, 0.73545 on Kaggle\n",
    "\n",
    "- top10_features: 0.826 on test, 0.70326 on Kaggle\n",
    "\n",
    "- top5_features: 0.7937 on test,  0.67985 on Kaggle\n",
    "\n",
    "- top2_features: 0.6045 on test, 0.49393 on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STEP 3: Train the KNN_pipe and Make predictions ########################\n",
    "rf_pipe.fit(data_train, data_train[target])\n",
    "\n",
    "pred = rf_pipe.predict(data_test)\n",
    "ID = data_test.Id\n",
    "\n",
    "# STEP 4: Write to file for Kaggle Submission #############################\n",
    "data_out = []\n",
    "for i in range(len(ID)):\n",
    "    data_out.append({'ID':ID.iloc[i], 'Cover_Type':pred[i]})\n",
    "\n",
    "import csv\n",
    "with open('test_submission_top2_rf_pipe.csv', 'wt') as fout:\n",
    "    cout = csv.DictWriter(fout, ['ID','Cover_Type'])\n",
    "    cout.writeheader()\n",
    "    cout.writerows(data_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Gradient Boosting Classifier\n",
    "\n",
    "## somehow not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(subsample=.7, n_estimators=100, max_depth=3, \n",
    "                                learning_rate=0.01, min_samples_leaf=1, random_state=3)\n",
    "\n",
    "gb.fit(df_train, df_train[target])\n",
    "\n",
    "y_pred_gb = gb.predict(df_test)  # get predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report_gb = classification_report(y_test, y_pred_gb)\n",
    "print(report_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross-validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_gb = cross_val_score(gb, df_train, df_train[target], cv=5)\n",
    "print(scores_gb.round(4))\n",
    "print(scores_gb.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion_gb = confusion_matrix(y_test, y_pred_gb, labels=[1,2,3,4,5,6,7])\n",
    "print(confusion_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    'max_depth': range(1,6),\n",
    "    'learning_rate': [.01, .05, .1],\n",
    "    'max_features': [2, 5, 'auto']\n",
    "}\n",
    "\n",
    "param_searcher = GridSearchCV(gb, parameter_grid, cv=5)\n",
    "param_searcher.fit(df_train, df_train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_searcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_searcher.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GradientBoostingClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vote_clf = VotingClassifier(estimators =[('knn', knn_pipe), ('lr', lr_pipe), ('rf', rf_pipe)])\n",
    "\n",
    "vote_clf.fit(df_train, df_train[target])\n",
    "\n",
    "y_pred_vote = vote_clf.predict(df_test)  # get predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report_vote = classification_report(y_test, y_pred_rf)\n",
    "print(report_vote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross-validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_vote = cross_val_score(vote_clf, df_train, df_train[target], cv=5)\n",
    "print(scores_vote.round(4))\n",
    "print(scores_vote.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion_vote = confusion_matrix(y_test, y_pred_vote, labels=[1,2,3,4,5,6,7])\n",
    "print(confusion_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
