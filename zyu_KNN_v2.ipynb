{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W207 Forest Cover - KNN v2\n",
    "\n",
    "## Plan\n",
    "\n",
    "#### Feature Engineering\n",
    "\n",
    "- More data cleaning, removing useless data columns\n",
    "\n",
    "- Feature engineering: using only the most important features\n",
    "\n",
    "- Feature engineering: combine some of the soil types\n",
    "\n",
    "#### Error Analysis\n",
    "\n",
    "- Confusion matrix: find out which types give the most problems\n",
    "\n",
    "- Any clue from EDA?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('train.csv')             # read training data\n",
    "data_test = pd.read_csv('test.csv')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(data_train, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Elevation', 'Aspect', 'Slope',\n",
       "       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
       "       'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n",
       "       'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points',\n",
       "       'Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3',\n",
       "       'Wilderness_Area4', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3',\n",
       "       'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8',\n",
       "       'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n",
       "       'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16',\n",
       "       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n",
       "       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n",
       "       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n",
       "       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n",
       "       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n",
       "       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40',\n",
       "       'Cover_Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to keep track of things\n",
    "target = df_train.columns[-1]\n",
    "all_features_ALL = df_train.columns[1:-1]\n",
    "\n",
    "num_features = df_train.columns[1:11]\n",
    "cat_features_ALL = df_train.columns[11:-1]\n",
    "\n",
    "wild_features = df_train.columns[11:15]\n",
    "soil_features_ALL = df_train.columns[15:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove constant Soil_Type7 and Soil_Type15\n",
    "all_features = all_features_ALL.drop(['Soil_Type7', 'Soil_Type15'])\n",
    "cat_features = cat_features_ALL.drop(['Soil_Type7', 'Soil_Type15'])\n",
    "soil_features = soil_features_ALL.drop(['Soil_Type7', 'Soil_Type15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top17_features = all_features_ALL[[0,5,9,13,3,4,6,1,8,7,23,51,16,2,52,10,12]]\n",
    "\n",
    "top10_features = all_features_ALL[[0,5,9,13,3,4,6,1,8,7]]\n",
    "\n",
    "top5_features = all_features_ALL[[0,5,9,13,3]]\n",
    "\n",
    "top2_features = all_features_ALL[[0,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Elevation', 'Horizontal_Distance_To_Roadways',\n",
       "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area4',\n",
       "       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
       "       'Hillshade_9am', 'Aspect', 'Hillshade_3pm', 'Hillshade_Noon',\n",
       "       'Soil_Type10', 'Soil_Type38', 'Soil_Type3', 'Slope', 'Soil_Type39',\n",
       "       'Wilderness_Area1', 'Wilderness_Area3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top17_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. KNN Pipeline\n",
    "\n",
    "- input a list of features\n",
    "\n",
    "- separate features into numeric and categorical\n",
    "\n",
    "- using StandardScaling on the numeric features\n",
    "\n",
    "- combine numeric and categorical features\n",
    "\n",
    "- PCA optional\n",
    "\n",
    "- fit KNN\n",
    "\n",
    "### Note:\n",
    "\n",
    "- Adding MinMaxScaler and Normalizer doesn't seem to help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
       "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
       "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
       "       'Horizontal_Distance_To_Fire_Points'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = top17_features\n",
    "\n",
    "num_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, Imputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def get_num_features(features):\n",
    "    num_features = [item for item in features if 'Soil' not in item and 'Wilderness' not in item ]\n",
    "    return num_features\n",
    "\n",
    "def get_cat_features(features):\n",
    "    cat_features = [item for item in features if 'Soil' in item or 'Wilderness' in item ]\n",
    "    return cat_features\n",
    "\n",
    "features = top17_features\n",
    "\n",
    "num_features = get_num_features(features)\n",
    "cat_features = get_cat_features(features)\n",
    "\n",
    "\n",
    "def select_num_features(X):\n",
    "    return X[num_features]\n",
    "\n",
    "def select_cat_features(X):\n",
    "    return X[cat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "num_feature_pipeline = Pipeline(steps=[\n",
    "    ('select', FunctionTransformer(select_num_features, validate=False)),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_feature_pipeline = Pipeline(steps=[\n",
    "    ('select', FunctionTransformer(select_cat_features, validate=False) )    \n",
    "])\n",
    "\n",
    "fu = FeatureUnion([\n",
    "    ('numeric', num_feature_pipeline),\n",
    "    ('categorical', cat_feature_pipeline)\n",
    "])\n",
    "\n",
    "knn_num = 2\n",
    "\n",
    "knn_pipe = Pipeline(steps=[\n",
    "    ('preprocess', fu),\n",
    "    ('predict', KNeighborsClassifier(n_neighbors=knn_num))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocess', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('numeric', Pipeline(steps=[('select', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function select_num_features at 0x113f3a400>,\n",
       "          inv_kw_args=None, inverse_func=None, kw_args=None, pass_y=False,\n",
       "          val...owski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pipe.fit(df_train, df_train[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis\n",
    "\n",
    "#### ROC curve is not applicable in this case, it is strictly restricted to binary cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = df_test[target]                # get correct labels\n",
    "y_pred_knn = knn_pipe.predict(df_test)  # get predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.78      0.68       552\n",
      "          2       0.65      0.51      0.57       561\n",
      "          3       0.65      0.79      0.71       530\n",
      "          4       0.89      0.89      0.89       563\n",
      "          5       0.80      0.84      0.82       513\n",
      "          6       0.83      0.61      0.71       529\n",
      "          7       0.93      0.87      0.90       532\n",
      "\n",
      "avg / total       0.76      0.75      0.75      3780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "F1_score_test = f1_score(y_test, y_pred, average='weighted').round(4)\n",
    "report_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "# print(F1_score_test)\n",
    "print(report_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross-validation score\n",
    "\n",
    "We would like to get a better estimate of the performance without contaminating the test data. Try using cross-validation to estimate the performance.\n",
    "\n",
    "(The results seem similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7367 0.7533 0.7451 0.7237 0.7466]\n",
      "0.7411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores_knn = cross_val_score(knn_pipe, df_train, df_train[target], cv=5)\n",
    "print(scores_knn.round(4))\n",
    "print(scores_knn.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[428  76   1   0  11   0  36]\n",
      " [184 286  18   1  64   8   0]\n",
      " [  4  18 421  29   9  49   0]\n",
      " [  0   0  57 500   0   6   0]\n",
      " [ 25  31  23   0 431   3   0]\n",
      " [  5  17 129  30  23 325   0]\n",
      " [ 55  14   0   0   1   0 462]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "\n",
    "confusion_knn = confusion_matrix(y_test, y_pred_knn, labels=[1,2,3,4,5,6,7])\n",
    "print(confusion_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commnets:\n",
    "\n",
    "- Cover_Types 4 and 7 have the best performance, from EDA, Cover_Type4 is the one live at the lowest elevation, Cover_Type7 is the one live at the highest elevation;\n",
    "\n",
    "- There is a lot of confusing between 1 and 2: they live in similar elevations just below 7, there is also a lot of confusion between 1 and 7;\n",
    "\n",
    "- Confusion between 6 and 3, 6 and 4 can also be explained by the closeness in elevation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Logistic Regression Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_pipe = Pipeline(steps=[\n",
    "    ('preprocess', fu),\n",
    "    ('predict', LogisticRegression(penalty='l2', C=2.0))\n",
    "])\n",
    "\n",
    "lr_pipe.fit(df_train, df_train[target])\n",
    "\n",
    "y_pred_lr = lr_pipe.predict(df_test)  # get predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.63      0.63       552\n",
      "          2       0.58      0.48      0.53       561\n",
      "          3       0.61      0.56      0.59       530\n",
      "          4       0.82      0.89      0.85       563\n",
      "          5       0.61      0.70      0.65       513\n",
      "          6       0.58      0.59      0.59       529\n",
      "          7       0.87      0.86      0.87       532\n",
      "\n",
      "avg / total       0.67      0.68      0.67      3780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_lr = classification_report(y_test, y_pred_lr)\n",
    "print(report_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross-validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6693 0.6789 0.6755 0.6708 0.6614]\n",
      "0.6712\n"
     ]
    }
   ],
   "source": [
    "scores_lr = cross_val_score(lr_pipe, df_train, df_train[target], cv=5)\n",
    "print(scores_lr.round(4))\n",
    "print(scores_lr.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[349  96   1   0  36   6  64]\n",
      " [128 269   9   0 126  24   5]\n",
      " [  0   2 297  71  15 145   0]\n",
      " [  0   0  30 503   0  30   0]\n",
      " [ 11  65  51   0 361  25   0]\n",
      " [  0  25  97  42  51 314   0]\n",
      " [ 66   5   0   0   2   0 459]]\n"
     ]
    }
   ],
   "source": [
    "confusion_lr = confusion_matrix(y_test, y_pred_lr, labels=[1,2,3,4,5,6,7])\n",
    "print(confusion_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Random Forest Pipeline\n",
    "\n",
    "### Note:\n",
    "\n",
    "- increase the RF n_estimators from 100 to 500 improves F1 score by 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_pipe = Pipeline(steps=[\n",
    "    ('preprocess', fu),\n",
    "    ('predict', RandomForestClassifier(n_estimators=500, n_jobs=-1, oob_score=True, random_state=121))\n",
    "])\n",
    "\n",
    "rf_pipe.fit(df_train, df_train[target])\n",
    "\n",
    "y_pred_rf = rf_pipe.predict(df_test)  # get predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.74      0.76       552\n",
      "          2       0.79      0.68      0.73       561\n",
      "          3       0.86      0.83      0.85       530\n",
      "          4       0.94      0.97      0.96       563\n",
      "          5       0.88      0.94      0.91       513\n",
      "          6       0.85      0.90      0.87       529\n",
      "          7       0.91      0.96      0.93       532\n",
      "\n",
      "avg / total       0.86      0.86      0.86      3780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "print(report_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross-validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8432 0.8533 0.862  0.8522 0.8455]\n",
      "0.8512\n"
     ]
    }
   ],
   "source": [
    "scores_rf = cross_val_score(rf_pipe, df_train, df_train[target], cv=5)\n",
    "print(scores_rf.round(4))\n",
    "print(scores_rf.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[410  79   0   0  10   3  50]\n",
      " [101 379  12   0  49  17   3]\n",
      " [  0   3 442  26   3  56   0]\n",
      " [  0   0  12 547   0   4   0]\n",
      " [  0  14   9   0 483   7   0]\n",
      " [  0   4  37   7   3 478   0]\n",
      " [ 18   2   0   0   0   0 512]]\n"
     ]
    }
   ],
   "source": [
    "confusion_rf = confusion_matrix(y_test, y_pred_rf, labels=[1,2,3,4,5,6,7])\n",
    "print(confusion_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(subsample=.7, n_estimators=100, max_depth=3, \n",
    "                                learning_rate=0.01, min_samples_leaf=1, random_state=3)\n",
    "\n",
    "gb.fit(df_train, df_train[target])\n",
    "\n",
    "y_pred_gb = gb.predict(df_test)  # get predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00       552\n",
      "          2       1.00      1.00      1.00       561\n",
      "          3       1.00      1.00      1.00       530\n",
      "          4       1.00      1.00      1.00       563\n",
      "          5       1.00      1.00      1.00       513\n",
      "          6       1.00      1.00      1.00       529\n",
      "          7       1.00      1.00      1.00       532\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_gb = classification_report(y_test, y_pred_gb)\n",
    "print(report_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross-validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "scores_gb = cross_val_score(gb, df_train, df_train[target], cv=5)\n",
    "print(scores_gb.round(4))\n",
    "print(scores_gb.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[552   0   0   0   0   0   0]\n",
      " [  0 561   0   0   0   0   0]\n",
      " [  0   0 530   0   0   0   0]\n",
      " [  0   0   0 563   0   0   0]\n",
      " [  0   0   0   0 513   0   0]\n",
      " [  0   0   0   0   0 529   0]\n",
      " [  0   0   0   0   0   0 532]]\n"
     ]
    }
   ],
   "source": [
    "confusion_gb = confusion_matrix(y_test, y_pred_gb, labels=[1,2,3,4,5,6,7])\n",
    "print(confusion_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    'max_depth': range(1,6),\n",
    "    'learning_rate': [.01, .05, .1],\n",
    "    'max_features': [2, 5, 'auto']\n",
    "}\n",
    "\n",
    "param_searcher = GridSearchCV(gb, parameter_grid, cv=5)\n",
    "param_searcher.fit(df_train, df_train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_searcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_searcher.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GradientBoostingClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vote_clf = VotingClassifier(estimators =[('knn', knn_pipe), ('lr', lr_pipe), ('rf', rf_pipe)])\n",
    "\n",
    "vote_clf.fit(df_train, df_train[target])\n",
    "\n",
    "y_pred_vote = vote_clf.predict(df_test)  # get predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.74      0.75       552\n",
      "          2       0.77      0.67      0.72       561\n",
      "          3       0.85      0.83      0.84       530\n",
      "          4       0.94      0.97      0.96       563\n",
      "          5       0.89      0.94      0.91       513\n",
      "          6       0.84      0.90      0.87       529\n",
      "          7       0.91      0.96      0.94       532\n",
      "\n",
      "avg / total       0.85      0.86      0.85      3780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_vote = classification_report(y_test, y_pred_rf)\n",
    "print(report_vote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross-validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7935 0.8189 0.8157 0.8058 0.7943]\n",
      "0.8056\n"
     ]
    }
   ],
   "source": [
    "scores_vote = cross_val_score(vote_clf, df_train, df_train[target], cv=5)\n",
    "print(scores_vote.round(4))\n",
    "print(scores_vote.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[406  79   1   0  13   4  49]\n",
      " [130 316  11   0  81  20   3]\n",
      " [  0   3 393  42   6  86   0]\n",
      " [  0   0  11 543   0   9   0]\n",
      " [  2  22  13   0 465  11   0]\n",
      " [  0   8  65  19   5 432   0]\n",
      " [ 31   2   0   0   2   0 497]]\n"
     ]
    }
   ],
   "source": [
    "confusion_vote = confusion_matrix(y_test, y_pred_vote, labels=[1,2,3,4,5,6,7])\n",
    "print(confusion_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
