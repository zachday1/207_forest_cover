{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W207 Forest Cover - KNN v2\n",
    "\n",
    "## Plan\n",
    "\n",
    "#### Feature Engineering\n",
    "\n",
    "- More data cleaning, removing useless data columns\n",
    "\n",
    "- Feature engineering: using only the most important features\n",
    "\n",
    "- Feature engineering: combine some of the soil types\n",
    "\n",
    "#### Error Analysis\n",
    "\n",
    "- Confusion matrix: find out which types give the most problems\n",
    "\n",
    "- Any clue from EDA?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('train.csv')             # read training data\n",
    "data_test = pd.read_csv('test.csv')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(data_train, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Elevation', 'Aspect', 'Slope',\n",
       "       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
       "       'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n",
       "       'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points',\n",
       "       'Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3',\n",
       "       'Wilderness_Area4', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3',\n",
       "       'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8',\n",
       "       'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n",
       "       'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16',\n",
       "       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n",
       "       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n",
       "       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n",
       "       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n",
       "       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n",
       "       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40',\n",
       "       'Cover_Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to keep track of things\n",
    "target = df_train.columns[-1]\n",
    "all_features_ALL = df_train.columns[1:-1]\n",
    "\n",
    "num_features = df_train.columns[1:11]\n",
    "cat_features_ALL = df_train.columns[11:-1]\n",
    "\n",
    "wild_features = df_train.columns[11:15]\n",
    "soil_features_ALL = df_train.columns[15:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove constant Soil_Type7 and Soil_Type15\n",
    "all_features = all_features_ALL.drop(['Soil_Type7', 'Soil_Type15'])\n",
    "cat_features = cat_features_ALL.drop(['Soil_Type7', 'Soil_Type15'])\n",
    "soil_features = soil_features_ALL.drop(['Soil_Type7', 'Soil_Type15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top17_features = all_features_ALL[[0,5,9,13,3,4,6,1,8,7,23,51,16,2,52,10,12]]\n",
    "\n",
    "top10_features = all_features_ALL[[0,5,9,13,3,4,6,1,8,7]]\n",
    "\n",
    "top5_features = all_features_ALL[[0,5,9,13,3]]\n",
    "\n",
    "top2_features = all_features_ALL[[0,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Elevation', 'Horizontal_Distance_To_Roadways',\n",
       "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area4',\n",
       "       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
       "       'Hillshade_9am', 'Aspect', 'Hillshade_3pm', 'Hillshade_Noon',\n",
       "       'Soil_Type10', 'Soil_Type38', 'Soil_Type3', 'Slope', 'Soil_Type39',\n",
       "       'Wilderness_Area1', 'Wilderness_Area3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top17_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. KNN Pipeline\n",
    "\n",
    "- input a list of features\n",
    "\n",
    "- separate features into numeric and categorical\n",
    "\n",
    "- using StandardScaling on the numeric features\n",
    "\n",
    "- combine numeric and categorical features\n",
    "\n",
    "- PCA optional\n",
    "\n",
    "- fit KNN\n",
    "\n",
    "### Note:\n",
    "\n",
    "- Adding MinMaxScaler and Normalizer doesn't seem to help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
       "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
       "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
       "       'Horizontal_Distance_To_Fire_Points'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = top17_features\n",
    "\n",
    "num_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, Imputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# STEP 1: Define the features  #########################################\n",
    "def get_num_features(features):\n",
    "    num_features = [item for item in features if 'Soil' not in item and 'Wilderness' not in item ]\n",
    "    return num_features\n",
    "\n",
    "def get_cat_features(features):\n",
    "    cat_features = [item for item in features if 'Soil' in item or 'Wilderness' in item ]\n",
    "    return cat_features\n",
    "\n",
    "features = top2_features\n",
    "\n",
    "num_features = get_num_features(features)\n",
    "cat_features = get_cat_features(features)\n",
    "\n",
    "\n",
    "# STEP 2: Define the KNN pipeline ######################################\n",
    "\n",
    "def select_num_features(X):\n",
    "    return X[num_features]\n",
    "\n",
    "def select_cat_features(X):\n",
    "    return X[cat_features]\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "num_feature_pipeline = Pipeline(steps=[\n",
    "    ('select', FunctionTransformer(select_num_features, validate=False)),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_feature_pipeline = Pipeline(steps=[\n",
    "    ('select', FunctionTransformer(select_cat_features, validate=False) )    \n",
    "])\n",
    "\n",
    "fu = FeatureUnion([\n",
    "    ('numeric', num_feature_pipeline),\n",
    "    ('categorical', cat_feature_pipeline)\n",
    "])\n",
    "\n",
    "knn_num = 10\n",
    "\n",
    "knn_pipe = Pipeline(steps=[\n",
    "    ('preprocess', fu),\n",
    "    ('predict', KNeighborsClassifier(n_neighbors=knn_num))\n",
    "])\n",
    "\n",
    "# knn_pipe.fit(df_train, df_train[target])\n",
    "\n",
    "# STEP 3: Train the KNN_pipe and Make predictions ########################\n",
    "knn_pipe.fit(data_train, data_train[target])\n",
    "\n",
    "pred = knn_pipe.predict(data_test)\n",
    "ID = data_test.Id\n",
    "\n",
    "# STEP 4: Write to file for Kaggle Submission #############################\n",
    "data_out = []\n",
    "for i in range(len(ID)):\n",
    "    data_out.append({'ID':ID.iloc[i], 'Cover_Type':pred[i]})\n",
    "\n",
    "import csv\n",
    "with open('test_submission_top2_knn_' + str(knn_num) + '.csv', 'wt') as fout:\n",
    "    cout = csv.DictWriter(fout, ['ID','Cover_Type'])\n",
    "    cout.writeheader()\n",
    "    cout.writerows(data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Scores of KNN Pipeline on Kaggle \n",
    "\n",
    "Use all_features, top17_features, top10_features, top5_features, top2_features and test the above pipeline with knn=1,2,5,10 and score on Kaggle, following are the results:\n",
    "\n",
    "### all_features\n",
    "\n",
    "- knn = 1: 0.6906\n",
    "\n",
    "- knn = 2: 0.68584\n",
    "\n",
    "- knn = 5: 0.64546\n",
    "\n",
    "- knn = 10: 0.61504\n",
    "\n",
    "\n",
    "### top17_features\n",
    "\n",
    "- knn = 1: 0.65998\n",
    "\n",
    "- knn = 2: 0.66320\n",
    "\n",
    "- knn = 5: 0.62491\n",
    "\n",
    "- knn = 10: 0.59760\n",
    "\n",
    "\n",
    "### top10_features\n",
    "\n",
    "- knn = 1: 0.63003\n",
    "\n",
    "- knn = 2: 0.63973\n",
    "\n",
    "- knn = 5: 0.59013\n",
    "\n",
    "- knn = 10: 0.55603\n",
    "\n",
    "\n",
    "### top5_features\n",
    "\n",
    "- knn = 1: 0.65710\n",
    "\n",
    "- knn = 2: 0.65603\n",
    "\n",
    "- knn = 5: 0.61171\n",
    "\n",
    "- knn = 10: 0.58272\n",
    "\n",
    "\n",
    "### top2_features\n",
    "\n",
    "- knn = 1: 0.48068\n",
    "\n",
    "- knn = 2: 0.52666\n",
    "\n",
    "- knn = 5: 0.50603\n",
    "\n",
    "- knn = 10: 0.50100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis\n",
    "\n",
    "#### ROC curve is not applicable in this case, it is strictly restricted to binary cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = df_test[target]                # get correct labels\n",
    "y_pred_knn = knn_pipe.predict(df_test)  # get predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.65      0.65       552\n",
      "          2       0.66      0.46      0.54       561\n",
      "          3       0.54      0.51      0.53       530\n",
      "          4       0.70      0.84      0.76       563\n",
      "          5       0.72      0.89      0.79       513\n",
      "          6       0.61      0.51      0.56       529\n",
      "          7       0.83      0.91      0.86       532\n",
      "\n",
      "avg / total       0.67      0.68      0.67      3780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "F1_score_test = f1_score(y_test, y_pred_knn, average='weighted').round(4)\n",
    "report_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "# print(F1_score_test)\n",
    "print(report_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross-validation score\n",
    "\n",
    "We would like to get a better estimate of the performance without contaminating the test data. Try using cross-validation to estimate the performance.\n",
    "\n",
    "(The results seem similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7367 0.7533 0.7451 0.7237 0.7466]\n",
      "0.7411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores_knn = cross_val_score(knn_pipe, df_train, df_train[target], cv=5)\n",
    "print(scores_knn.round(4))\n",
    "print(scores_knn.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[359  72   2   0  29   1  89]\n",
      " [143 257  35   0  98  15  13]\n",
      " [  0  17 271 110  22 110   0]\n",
      " [  0   0  56 474   0  33   0]\n",
      " [  3  29  14   0 455  12   0]\n",
      " [  1  12 121  95  28 272   0]\n",
      " [ 47   2   0   0   0   0 483]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "\n",
    "confusion_knn = confusion_matrix(y_test, y_pred_knn, labels=[1,2,3,4,5,6,7])\n",
    "print(confusion_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commnets:\n",
    "\n",
    "- Cover_Types 4 and 7 have the best performance, from EDA, Cover_Type4 is the one live at the lowest elevation, Cover_Type7 is the one live at the highest elevation;\n",
    "\n",
    "- There is a lot of confusing between 1 and 2: they live in similar elevations just below 7, there is also a lot of confusion between 1 and 7;\n",
    "\n",
    "- Confusion between 6 and 3, 6 and 4 can also be explained by the closeness in elevation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Logistic Regression Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_pipe = Pipeline(steps=[\n",
    "    ('preprocess', fu),\n",
    "    ('predict', LogisticRegression(penalty='l2', C=2.0))\n",
    "])\n",
    "\n",
    "lr_pipe.fit(df_train, df_train[target])\n",
    "\n",
    "y_pred_lr = lr_pipe.predict(df_test)  # get predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_lr = classification_report(y_test, y_pred_lr)\n",
    "print(report_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross-validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_lr = cross_val_score(lr_pipe, df_train, df_train[target], cv=5)\n",
    "print(scores_lr.round(4))\n",
    "print(scores_lr.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_lr = confusion_matrix(y_test, y_pred_lr, labels=[1,2,3,4,5,6,7])\n",
    "print(confusion_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Random Forest Pipeline\n",
    "\n",
    "### Note:\n",
    "\n",
    "- increase the RF n_estimators from 100 to 500 improves F1 score by 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_pipe = Pipeline(steps=[\n",
    "    ('preprocess', fu),\n",
    "    ('predict', RandomForestClassifier(n_estimators=500, n_jobs=-1, oob_score=True, random_state=121))\n",
    "])\n",
    "\n",
    "rf_pipe.fit(df_train, df_train[target])\n",
    "\n",
    "y_pred_rf = rf_pipe.predict(df_test)  # get predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "print(report_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross-validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_rf = cross_val_score(rf_pipe, df_train, df_train[target], cv=5)\n",
    "print(scores_rf.round(4))\n",
    "print(scores_rf.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_rf = confusion_matrix(y_test, y_pred_rf, labels=[1,2,3,4,5,6,7])\n",
    "print(confusion_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Gradient Boosting Classifier\n",
    "\n",
    "## somehow not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(subsample=.7, n_estimators=100, max_depth=3, \n",
    "                                learning_rate=0.01, min_samples_leaf=1, random_state=3)\n",
    "\n",
    "gb.fit(df_train, df_train[target])\n",
    "\n",
    "y_pred_gb = gb.predict(df_test)  # get predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_gb = classification_report(y_test, y_pred_gb)\n",
    "print(report_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross-validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_gb = cross_val_score(gb, df_train, df_train[target], cv=5)\n",
    "print(scores_gb.round(4))\n",
    "print(scores_gb.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_gb = confusion_matrix(y_test, y_pred_gb, labels=[1,2,3,4,5,6,7])\n",
    "print(confusion_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    'max_depth': range(1,6),\n",
    "    'learning_rate': [.01, .05, .1],\n",
    "    'max_features': [2, 5, 'auto']\n",
    "}\n",
    "\n",
    "param_searcher = GridSearchCV(gb, parameter_grid, cv=5)\n",
    "param_searcher.fit(df_train, df_train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_searcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_searcher.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GradientBoostingClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vote_clf = VotingClassifier(estimators =[('knn', knn_pipe), ('lr', lr_pipe), ('rf', rf_pipe)])\n",
    "\n",
    "vote_clf.fit(df_train, df_train[target])\n",
    "\n",
    "y_pred_vote = vote_clf.predict(df_test)  # get predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_vote = classification_report(y_test, y_pred_rf)\n",
    "print(report_vote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross-validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_vote = cross_val_score(vote_clf, df_train, df_train[target], cv=5)\n",
    "print(scores_vote.round(4))\n",
    "print(scores_vote.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_vote = confusion_matrix(y_test, y_pred_vote, labels=[1,2,3,4,5,6,7])\n",
    "print(confusion_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
