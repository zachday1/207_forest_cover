{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Park Rangers: Forest Classification Kaggle Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEED TO CLEAN THIS UP\n",
    "import math\n",
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as skl\n",
    "import csv\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics, cross_validation\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, Imputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Understanding (PKB)\n",
    "\n",
    "- What problem are we trying solve?\n",
    "- What are the relevant metrics? How much do we plan to improve them?\n",
    "- What will we deliver?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Understanding (ZY)\n",
    "\n",
    "- What are the raw data sources?\n",
    "- What does each 'unit' (e.g. row) of data represent?\n",
    "- What are the fields (columns)?\n",
    "- EDA\n",
    "  - Distribution of each feature\n",
    "  - Missing values\n",
    "  - Distribution of target\n",
    "  - Relationships between features\n",
    "  - Other idiosyncracies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### statistical description\n",
    "\n",
    "- No missing values. every row can be used.\n",
    "- Vertical_Distance_To_Hydrology has negative values.\n",
    "- Wilderness_Area and Soil_Type are one-hot encoded, they could be converted back for some analysis.\n",
    "- Soil_Type7 and Soil_Type15 can be removed as they are constant (all zeros)\n",
    "- Scales are not the same for all, rescaling and standardization may be helpful for some algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('train.csv')             # read training data\n",
    "data_test = pd.read_csv('test.csv')\n",
    "\n",
    "df_train, df_test = train_test_split(data_train, random_state=1)\n",
    "\n",
    "# classification is target\n",
    "target = df_train.columns[-1]\n",
    "#remove ID\n",
    "all_features_ALL = df_train.columns[1:-1]\n",
    "\n",
    "#seperate features by data type\n",
    "num_features = df_train.columns[1:11]\n",
    "cat_features_ALL = df_train.columns[11:-1]\n",
    "\n",
    "#seperate binary features by classification covered\n",
    "wild_features = df_train.columns[11:15]\n",
    "soil_features_ALL = df_train.columns[15:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[num_features].hist(figsize=(16,12), bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### skew\n",
    "\n",
    "- values close to 0 show less skew\n",
    "\n",
    "- several features in Soil_Type show a large skew. Hence, some algorithms may benefit if skew corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.skew().plot(kind='bar', figsize=(15,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class distribution\n",
    "\n",
    "- all classes have the same number, no class-rebalancing is necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby('Cover_Type').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Correlations\n",
    "\n",
    "- Correlation requires continuous data, ignore Wilderness_Area and Soil_Type here.\n",
    "\n",
    "- strong correlation observed for following pairs, opportunity to reduce features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = num_features.shape[0]         # size: 10 numeric features\n",
    "num_data = df_train[num_features]    #  selecting numeric features\n",
    "\n",
    "num_data_cor = num_data.corr()       # correlation matrix\n",
    "\n",
    "cor_threshold = 0.5                  # threshold for selecting highly correlated features\n",
    "num_data_cor_high = []               # list for pairs with cor > threshold\n",
    "\n",
    "# search for highly correlated pairs\n",
    "for i in range(0, size):\n",
    "    for j in range(i+1, size):\n",
    "        if abs(num_data_cor.iloc[i,j]) >= cor_threshold:                  \n",
    "            num_data_cor_high.append([num_data_cor.iloc[i,j], i, j])  # store correlation\n",
    "            \n",
    "# sort to show high ones\n",
    "num_data_cor_high_sorted = sorted(num_data_cor_high, key = lambda x: -abs(x[0]))\n",
    "\n",
    "# print correlation and column names\n",
    "for v, i, j in num_data_cor_high_sorted:\n",
    "    print(\"{} & {} = {:.2f}\".format(num_features[i], num_features[j], v))\n",
    "\n",
    "# correlation heat map\n",
    "fig, ax = plt.subplots(figsize=(8, 8))  \n",
    "sns.heatmap(num_data_cor, square=True, linewidths=1)\n",
    "plt.title('Correlation of Numeric Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cm.jet\n",
    "\n",
    "labels = df_train.Cover_Type\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20,10))\n",
    "\n",
    "df_train.plot(kind='scatter', x='Elevation', y='Horizontal_Distance_To_Roadways',\n",
    "              marker='o', c=labels, cmap=cmap, colorbar=False, ax=axes[0])\n",
    "\n",
    "df_train.plot(kind='scatter', x='Elevation', y='Aspect', \n",
    "              marker='o', c=labels, cmap=cmap, colorbar=False, ax=axes[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = df_train.columns.tolist()\n",
    "\n",
    "A = np.array(col_names)\n",
    "\n",
    "soil_types = [item for item in A if \"Soil\" in item]\n",
    "wilderness_areas = [item for item in A if \"Wilderness_Area\" in item]\n",
    "\n",
    "# Which wilderness_area support which cover_types?\n",
    "\n",
    "for wilderness_area in wilderness_areas: print(wilderness_area, df_train[wilderness_area].sum())\n",
    "\n",
    "wild_areas_sum = df_train[wilderness_areas].groupby(df_train['Cover_Type']).sum()\n",
    "wild_areas_sum.T.plot(kind='bar', stacked=True, figsize=(10,6), cmap='jet')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which soil_types support which cover_types?\n",
    "\n",
    "# for soil_type in soil_types: print (soil_type, df_train[soil_type].sum())\n",
    "\n",
    "types_sum = df_train[soil_types].groupby(df_train['Cover_Type']).sum()\n",
    "types_sum.T.plot(kind='bar', stacked=True, figsize=(15,6), cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "- What steps are taken to prepare the data for modeling?\n",
    "  - feature transformations? engineering?\n",
    "  - table joins? aggregation?\n",
    "- Precise description of modeling base tables.\n",
    "  - What are the rows/columns of X (the predictors)?\n",
    "  - What is y (the target)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove constant Soil_Type7 and Soil_Type15 because they do not have data\n",
    "all_features = all_features_ALL.drop(['Soil_Type7', 'Soil_Type15'])\n",
    "cat_features = cat_features_ALL.drop(['Soil_Type7', 'Soil_Type15'])\n",
    "soil_features = soil_features_ALL.drop(['Soil_Type7', 'Soil_Type15'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Define the features  #########################################\n",
    "def get_num_features(features):\n",
    "    num_features = [item for item in features if 'Soil' not in item and 'Wilderness' not in item ]\n",
    "    return num_features\n",
    "\n",
    "def get_cat_features(features):\n",
    "    cat_features = [item for item in features if 'Soil' in item or 'Wilderness' in item ]\n",
    "    return cat_features\n",
    "\n",
    "features = all_features\n",
    "\n",
    "num_features = get_num_features(features)\n",
    "cat_features = get_cat_features(features)\n",
    "\n",
    "def select_num_features(X):\n",
    "    return X[num_features]\n",
    "\n",
    "def select_cat_features(X):\n",
    "    return X[cat_features]\n",
    "\n",
    "num_feature_pipeline = Pipeline(steps=[\n",
    "    ('select', FunctionTransformer(select_num_features, validate=False)),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_feature_pipeline = Pipeline(steps=[\n",
    "    ('select', FunctionTransformer(select_cat_features, validate=False) )    \n",
    "])\n",
    "\n",
    "fu = FeatureUnion([\n",
    "    ('numeric', num_feature_pipeline),\n",
    "    ('categorical', cat_feature_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling\n",
    "\n",
    "- What model are we using? Why?\n",
    "- Assumptions?\n",
    "- Regularization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Logistic Regression (PKB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline(steps=[\n",
    "    ('preprocess', fu),\n",
    "    ('predict', LogisticRegression(penalty='l2', C=2.0))\n",
    "])\n",
    "\n",
    "lr_pipe.fit(df_train, df_train[target])\n",
    "\n",
    "y_pred_lr = lr_pipe.predict(df_test)  # get predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr_pipe_pca = Pipeline(steps=[\n",
    "    ('preprocess', fu),\n",
    "    ('pca', PCA(n_components= 52)),\n",
    "    ('predict', LogisticRegression(penalty='l2', C=2.0))\n",
    "])\n",
    "\n",
    "lr_pipe_pca.fit(df_train, df_train[target])\n",
    "\n",
    "y_pred_lr_pca = lr_pipe_pca.predict(df_test)  # get predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6713\n",
      "44\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11665a588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def best_components(n_features):\n",
    "    lr_pipe = Pipeline(steps=[\n",
    "        ('preprocess', fu),\n",
    "        ('pca', PCA(n_components= n_features)),\n",
    "        ('predict', LogisticRegression(penalty='l2', C=2.0))\n",
    "    ])\n",
    "\n",
    "    lr_pipe.fit(df_train, df_train[target])\n",
    "    \n",
    "    scores_lr = cross_val_score(lr_pipe, df_train, df_train[target], cv=2)\n",
    "    return scores_lr.mean().round(4)\n",
    "\n",
    "out = [best_components(i) for i in range(1, 52)]\n",
    "\n",
    "plt.plot(out)\n",
    "print(np.max(out))\n",
    "print(np.argmax(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 KNN (ZY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 SVM (ZY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 RF (ZD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 AdaBoost (ZY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "- How well does the model perform?\n",
    "  - Accuracy\n",
    "  - ROC curves\n",
    "  - Cross-validation\n",
    "  - other metrics? performance?\n",
    "\n",
    "- AB test results (if any)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Logistic Regression (PKB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.63      0.63       552\n",
      "          2       0.58      0.48      0.53       561\n",
      "          3       0.61      0.56      0.58       530\n",
      "          4       0.82      0.89      0.85       563\n",
      "          5       0.61      0.70      0.65       513\n",
      "          6       0.58      0.59      0.59       529\n",
      "          7       0.86      0.87      0.87       532\n",
      "\n",
      "avg / total       0.67      0.67      0.67      3780\n",
      "\n",
      "[0.6693 0.6789 0.6755 0.6708 0.6614]\n",
      "0.6712\n"
     ]
    }
   ],
   "source": [
    "#base log F1\n",
    "y_test = df_test[target]                # get correct labels\n",
    "report_lr = classification_report(y_test, y_pred_lr)\n",
    "print(report_lr)\n",
    "#base log cross validation\n",
    "scores_lr = cross_val_score(lr_pipe, df_train, df_train[target], cv=5)\n",
    "print(scores_lr.round(4))\n",
    "print(scores_lr.mean().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[351  94   1   0  38   6  62]\n",
      " [128 274  10   0 119  25   5]\n",
      " [  0   2 292  75  15 146   0]\n",
      " [  0   0  28 507   0  28   0]\n",
      " [  9  68  46   0 363  27   0]\n",
      " [  0  19  99  42  47 322   0]\n",
      " [ 66   4   0   0   2   0 460]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr = lr_pipe.predict(df_test)\n",
    "confusion_lr = confusion_matrix(y_test, y_pred_lr, labels=[1,2,3,4,5,6,7])\n",
    "print(confusion_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Train the lr_pipe and Make predictions ########################\n",
    "lr_pipe.fit(data_train, data_train[target])\n",
    "\n",
    "pred = lr_pipe.predict(data_test)\n",
    "ID = data_test.Id\n",
    "\n",
    "# STEP 4: Write to file for Kaggle Submission #############################\n",
    "data_out = []\n",
    "for i in range(len(ID)):\n",
    "    data_out.append({'ID':ID.iloc[i], 'Cover_Type':pred[i]})\n",
    "\n",
    "import csv\n",
    "with open('base_log_model.csv', 'wt') as fout:\n",
    "    cout = csv.DictWriter(fout, ['ID','Cover_Type'])\n",
    "    cout.writeheader()\n",
    "    cout.writerows(data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.63      0.63       552\n",
      "          2       0.58      0.48      0.53       561\n",
      "          3       0.61      0.56      0.58       530\n",
      "          4       0.82      0.89      0.85       563\n",
      "          5       0.61      0.70      0.65       513\n",
      "          6       0.58      0.59      0.59       529\n",
      "          7       0.87      0.86      0.87       532\n",
      "\n",
      "avg / total       0.67      0.67      0.67      3780\n",
      "\n",
      "[0.6689 0.6793 0.675  0.6708 0.6614]\n",
      "0.6711\n"
     ]
    }
   ],
   "source": [
    "#base log F1\n",
    "y_test = df_test[target]                # get correct labels\n",
    "report_lr_pca = classification_report(y_test, y_pred_lr_pca)\n",
    "print(report_lr_pca)\n",
    "#base log cross validation\n",
    "scores_lr_pca = cross_val_score(lr_pipe_pca, df_train, df_train[target], cv=5)\n",
    "print(scores_lr_pca.round(4))\n",
    "print(scores_lr_pca.mean().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[351  94   1   0  38   6  62]\n",
      " [127 275  10   0 119  25   5]\n",
      " [  0   2 292  75  15 146   0]\n",
      " [  0   0  28 508   0  27   0]\n",
      " [  9  68  46   0 363  27   0]\n",
      " [  0  19  99  42  47 322   0]\n",
      " [ 66   4   0   0   2   0 460]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr_pca = lr_pipe_pca.predict(df_test)\n",
    "confusion_lr_pca = confusion_matrix(y_test, y_pred_lr_pca, labels=[1,2,3,4,5,6,7])\n",
    "print(confusion_lr_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Train the lr_pipe and Make predictions ########################\n",
    "lr_pipe_pca.fit(data_train, data_train[target])\n",
    "\n",
    "pred = lr_pipe_pca.predict(data_test)\n",
    "ID = data_test.Id\n",
    "\n",
    "# STEP 4: Write to file for Kaggle Submission #############################\n",
    "data_out = []\n",
    "for i in range(len(ID)):\n",
    "    data_out.append({'ID':ID.iloc[i], 'Cover_Type':pred[i]})\n",
    "\n",
    "import csv\n",
    "with open('pca_log_model.csv', 'wt') as fout:\n",
    "    cout = csv.DictWriter(fout, ['ID','Cover_Type'])\n",
    "    cout.writeheader()\n",
    "    cout.writerows(data_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 KNN (ZY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 SVM (ZY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 RF (ZD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 AdaBoost (ZY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Deployment\n",
    "\n",
    "- How is the model deployed?\n",
    "  - prediction service?\n",
    "  - serialized model?\n",
    "  - regression coefficients?\n",
    "- What support is provided after initial deployment?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
